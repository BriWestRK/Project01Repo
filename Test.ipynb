{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5c177f-cba3-4a5c-aaec-f16376247766",
   "metadata": {},
   "source": [
    "1) Sanity: right Python + packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fc48e-af95-46b5-93d4-d05207fcf8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Exe   : C:\\PythonProjects\\Project01\\.venv\\Scripts\\python.exe\n",
      "Site  : ['C:\\\\PythonProjects\\\\Project01\\\\.venv', 'C:\\\\PythonProjects\\\\Project01\\\\.venv\\\\Lib\\\\site-packages']\n",
      "Platform: Windows-11-10.0.22631-SP0\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import site\n",
    "import sys\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Exe   :\", sys.executable)\n",
    "print(\"Site  :\", site.getsitepackages() if hasattr(site, \"getsitepackages\") else \"n/a\")\n",
    "print(\"Platform:\", platform.platform())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2a90-4626-4220-9546-459886deb4e3",
   "metadata": {},
   "source": [
    "You want Exe to point to C:\\PythonProjects\\Project01\\.venv\\Scripts\\python.exe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7797c56-82ba-477a-baa1-a3d2e21fb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai -> OK\n",
      "langchain -> OK\n",
      "langchain_openai -> OK\n",
      "langchain_community -> OK\n",
      "tiktoken -> OK\n"
     ]
    }
   ],
   "source": [
    "# Confirm the exact packages you’re using in THIS kernel\n",
    "import importlib.util\n",
    "\n",
    "for pkg in [\"openai\",\"langchain\",\"langchain_openai\",\"langchain_community\",\"tiktoken\"]:\n",
    "    found = importlib.util.find_spec(pkg) is not None\n",
    "    print(pkg, \"->\", \"OK\" if found else \"MISSING\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a108ea-229f-4328-8714-31cac80497d0",
   "metadata": {},
   "source": [
    "If anything shows MISSING, install from a terminal with the venv active:\n",
    "pip install --upgrade openai langchain langchain-openai langchain-community tiktoken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635c609-ed23-4465-9679-e2c2d2bf85b8",
   "metadata": {},
   "source": [
    "2) Does your notebook see the environment variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd229e4-45b6-4537-bce5-cbec67791bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY present? -> True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"OPENAI_API_KEY present? ->\", bool(os.getenv(\"OPENAI_API_KEY\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9fc3d-e225-473f-86b6-1a122ad3f8c6",
   "metadata": {},
   "source": [
    "False? You either set it in a different shell or set it after you launched Jupyter.\n",
    "\n",
    "Fix: close Jupyter, reopen from the activated venv; or in the notebook, temporarily do:\n",
    "import os; os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"   # for this kernel session only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4342336-aa83-494f-94cc-abdc504d547a",
   "metadata": {},
   "source": [
    "3) Direct OpenAI API smoke test (bypasses LangChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4650c5-d49e-429a-96cc-b8cf8b5c5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model count: 84\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from env\n",
    "\n",
    "# Auth + connectivity check\n",
    "models = client.models.list()\n",
    "print(\"Model count:\", len(models.data))\n",
    "\n",
    "# Minimal chat call\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Reply with the word OK\"}],\n",
    ")\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2a30c-9f9d-4b1e-aa81-7d088b462277",
   "metadata": {},
   "source": [
    "big test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18476ba9-33da-4ab0-b3fe-5c78f83dc525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! If you\\'re looking to get started with LangChain in a fresh Python virtual environment (venv), I can guide you through the setup process. Here’s a step-by-step guide:\\n\\n### Step 1: Set Up a Virtual Environment\\n\\n1. **Create a new virtual environment:**\\n   Open your terminal and navigate to the desired directory where you want to create the virtual environment. Then run:\\n\\n   ```bash\\n   python -m venv langchain-env\\n   ```\\n\\n2. **Activate the virtual environment:**\\n   - On Windows:\\n     ```bash\\n     langchain-env\\\\Scripts\\\\activate\\n     ```\\n   - On macOS/Linux:\\n     ```bash\\n     source langchain-env/bin/activate\\n     ```\\n\\n### Step 2: Install LangChain\\n\\n3. **Install LangChain:**\\n   With your virtual environment activated, install LangChain using pip:\\n\\n   ```bash\\n   pip install langchain\\n   ```\\n\\n4. **(Optional) Install other dependencies:**\\n   Depending on what features you want to use in LangChain, you might also need to install additional packages. For example, if you plan to use OpenAI\\'s GPT models, you might need the `openai` package:\\n\\n   ```bash\\n   pip install openai\\n   ```\\n\\n   If you want to use other integrations or features, consult the LangChain documentation for additional requirements.\\n\\n### Step 3: Verify Installation\\n\\n5. **Check the installation:**\\n   You can verify if LangChain has been installed correctly by running the following command in Python:\\n\\n   ```python\\n   python -c \"import langchain; print(langchain.__version__)\"\\n   ```\\n\\n### Step 4: Start Using LangChain\\n\\n6. **Create a new Python file and start coding:**\\n   You can now create a Python file (e.g., `app.py`) and start building your application using LangChain.\\n\\n### Example Code Snippet\\n\\nHere\\'s a simple example to get you started with LangChain:\\n\\n```python\\nfrom langchain import LLMChain, OpenAI\\n\\n# Initialize the OpenAI model (ensure you have set your OpenAI API key)\\nmodel = OpenAI(temperature=0.7)\\n\\n# Create a chain\\nchain = LLMChain(llm=model)\\n\\n# Call the chain with a prompt\\nresponse = chain.run(\"Tell me a joke!\")\\nprint(response)\\n```\\n\\n### Step 5: Deactivate the Virtual Environment\\n\\nWhen you\\'re done working in the virtual environment, you can deactivate it by running:\\n\\n```bash\\ndeactivate\\n```\\n\\nThat\\'s it! You\\'re all set up to start using LangChain in your fresh virtual environment. If you have any questions or need further assistance, feel free to ask!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 554, 'prompt_tokens': 17, 'total_tokens': 571, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CLsq3RAHYYEY2IsMMYM2vXecAPDHR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--ad2d2990-dced-4e48-b7a6-c4e868463032-0' usage_metadata={'input_tokens': 17, 'output_tokens': 554, 'total_tokens': 571, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")  # or gpt-3.5-turbo if you prefer\n",
    "resp = llm.invoke(\"Hello, LangChain in a fresh venv!\")\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8adb3b-4de2-48b1-bb36-c7be80642150",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bd460e-045b-4ed7-b1ea-0d3a7ddd8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be77a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
