{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de5d9ae-eeed-4bff-b74f-75dd86b0da95",
   "metadata": {},
   "source": [
    "Follow on from 05: \n",
    "Summary: Multi-Step Workflow with LCEL\n",
    "Overview\n",
    "This exercise demonstrates how to build a more complex, multi-step workflow using the LangChain Expression Language (LCEL). The project involves generating business ideas, analyzing them for strengths and weaknesses, and producing a structured business report, all through interconnected chains.\n",
    "\n",
    "Key Steps Covered\n",
    "1. Initial Setup\n",
    "All necessary imports and environment configurations are completed.\n",
    "LCEL components such as RunnableParallel, pipe, and message parsing utilities are ready for use.\n",
    "2. Idea Generation Chain\n",
    "A prompt template is created to generate a business idea based on a given industry.\n",
    "The chain uses:\n",
    "The idea prompt\n",
    "A language model (llm)\n",
    "An output parser to structure the result\n",
    "idea_chain = idea_prompt | llm | parse\n",
    "Invoking the chain with an example input like \"agro\" produces an innovative business idea and a brief description.\n",
    "3. Business Idea Analysis Chain\n",
    "A second prompt template is created to analyze the generated business idea.\n",
    "\n",
    "The analysis prompt asks for:\n",
    "\n",
    "Three key strengths\n",
    "Three potential weaknesses\n",
    "This chain follows the same structure: prompt → model → parser.\n",
    "\n",
    "analysis_chain = analysis_prompt | llm | parse\n",
    "The output lists the strengths and weaknesses of the business idea clearly.\n",
    "4. Business Report Generation Chain\n",
    "A structured prompt and Pydantic model are used to create a business report from the analysis.\n",
    "The report uses function calling to ensure structured output:\n",
    "A Report class is defined with strengths and weaknesses fields.\n",
    "class Report(BaseModel):\n",
    "  strengths: List[str]\n",
    "  weaknesses: List[str]\n",
    "The report chain builds a structured final report from the analysis results.\n",
    "report_chain = report_prompt | llm.with_structured_output(Report)\n",
    "5. Building the End-to-End Workflow\n",
    "An overall end-to-end chain combines:\n",
    "\n",
    "idea_chain\n",
    "analysis_chain\n",
    "report_chain\n",
    "This composite chain takes an industry input and produces a complete, structured business report in one invocation.\n",
    "\n",
    "end_to_end_chain = idea_chain | analysis_chain | report_chain\n",
    "Testing the full chain with \"agro\" yields:\n",
    "An innovative idea\n",
    "An analysis\n",
    "A final structured report\n",
    "6. Encouraged Exploration\n",
    "Learners are encouraged to:\n",
    "Add memory modules to track multiple interactions.\n",
    "Explore additional runnables to expand the workflow.\n",
    "Integrate even more complex processing steps or refine output formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6bcd7-6ee6-4e37-b3bf-b21b03415d71",
   "metadata": {},
   "source": [
    "## Introduction to Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c45bea-6eb3-4ea6-8794-5fe4cbdf5984",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) enhances language models by providing external context from a retrieval system before generating responses. This approach improves accuracy and reduces hallucinations by grounding responses in relevant information.\n",
    "\n",
    "How RAG Works\n",
    "RAG pipelines consist of three main components:\n",
    "\n",
    "Retrieval – Searches a database or document corpus to find relevant information. Uses vector search or keyword matching.\n",
    "\n",
    "Augmentation – Combines retrieved documents with the user’s query in a structured prompt.\n",
    "\n",
    "Generation – The LLM generates a response using both the query and retrieved context.\n",
    "\n",
    "Building a RAG Pipeline\n",
    "A RAG system requires both an offline indexing phase and an online retrieval phase.\n",
    "\n",
    "Indexing (Offline Phase)\n",
    "Before retrieval can happen, documents must be processed and stored efficiently:\n",
    "\n",
    "Document Loaders – Extract raw data from files, APIs, or databases.\n",
    "Text Splitters – Divide large documents into smaller, searchable chunks.\n",
    "VectorStore & Embeddings – Convert text into vector representations and store them for fast retrieval.\n",
    "Retrieval & Augmented Generation (Online Phase)\n",
    "When a user submits a query, the system:\n",
    "\n",
    "Searches the VectorStore for relevant document chunks.\n",
    "\n",
    "Incorporates retrieved text into a structured prompt.\n",
    "\n",
    "Generates an informed response using the LLM.\n",
    "\n",
    "Applications of RAG\n",
    "Customer Support – AI chatbots retrieve relevant FAQ responses.\n",
    "Content Creation – AI-assisted writing tools generate fact-based content.\n",
    "Research & Knowledge Management – Quickly synthesize insights from large datasets.\n",
    "Design Considerations\n",
    "Ensure retrieval quality – Poorly selected documents lead to irrelevant outputs.\n",
    "Optimize text chunking – Too small, and key details get lost; too large, and retrieval suffers.\n",
    "Manage LLM context limits – Retrieved text must fit within the model’s processing window.\n",
    "Final Thoughts\n",
    "RAG significantly improves the accuracy, efficiency, and trustworthiness of AI-generated content. By combining retrieval systems with generative models, applications can deliver more precise and context-aware responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa44f4b-e5e6-4ea5-931d-9f16202393a2",
   "metadata": {},
   "source": [
    "Demo: RAG pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7ef822-d5ff-45e5-991a-83e71c244f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders.wikipedia import WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7ca22-543b-4c8a-8c06-a5dfba8e7bca",
   "metadata": {},
   "source": [
    "1. Setting the Stage: Defining the Data Source\n",
    "Wikipedia is used as the external knowledge source.\n",
    "A search query retrieves a document about Anthony Hopkins.\n",
    "Only one document is retrieved initially, containing a significant amount of text.\n",
    "docs = wikipedia_search(\"Anthony Hopkins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd6d5d-050c-43da-b973-2c2cfaa80021",
   "metadata": {},
   "source": [
    "Loader, getting the source text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d377469-00f4-4c04-89d3-5e94f23c23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WikipediaLoader(\n",
    "    \"Anthony_Hopkins\",\n",
    "    load_max_docs=1,\n",
    "    doc_content_chars_max=40000\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91cbe47-a2c0-4572-96cf-848007bff38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692b268f-186e-45a9-9909-1149acb7760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38910"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c88ad2-4730-41f0-8d33-ec49f1248575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d7483-3f25-4c2b-93cd-7fb753ed6742",
   "metadata": {},
   "source": [
    "2. Splitting Documents into Chunks\n",
    "Large documents are split into smaller segments using a text splitter.\n",
    "Smaller chunks improve retrieval accuracy by narrowing the search space.\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "Example: One document is split into 182 sub-documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0f0d15-b423-4dc5-8e7a-1510ab706889",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9015388-92f3-4212-96a8-589a2f60aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Wikipedia page into 182 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Split Wikipedia page into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefd1e35-90ce-4497-9ad3-3a8489d7a319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'title': 'Anthony Hopkins', 'summary': \"Sir Philip Anthony Hopkins (born 31 December 1937) is a Welsh actor. Considered one of Britain's most recognisable and prolific actors, he is known for his performances on the screen and stage. Hopkins has received numerous accolades, including two Academy Awards, four BAFTA Awards, two Primetime Emmy Awards, and a Laurence Olivier Award. He has also received the Cecil B. DeMille Award in 2005 and the BAFTA Fellowship for lifetime achievement in 2008. He was knighted by Queen Elizabeth II for his services to drama in 1993.\\nAfter graduating from the Royal Welsh College of Music & Drama in 1957, Hopkins trained at RADA (the Royal Academy of Dramatic Art) in London. He was then spotted by Laurence Olivier, who invited him to join the Royal National Theatre in 1965. Productions at the National included King Lear (his favourite Shakespeare play), Coriolanus, Macbeth, and Antony and Cleopatra. In 1985, he received acclaim and a Laurence Olivier Award for his performance in the David Hare play Pravda. His last stage play was a West End production of M. Butterfly in 1989.\\nHopkins' early film roles include The Lion in Winter (1968), A Bridge Too Far (1977), Magic (1978), and The Elephant Man (1980). He won two Academy Awards for Best Actor for playing Hannibal Lecter in the horror thriller The Silence of the Lambs (1991) and an octogenarian with dementia in the psychological drama The Father (2020). He was also Oscar-nominated for The Remains of the Day (1993), Nixon (1995), Amistad (1997), and The Two Popes (2019). Other notable films include 84 Charing Cross Road (1987), Howards End (1992), Bram Stoker's Dracula (1992), Shadowlands (1993), Legends of the Fall (1994), The Mask of Zorro (1998), and the Marvel Cinematic Universe's Thor films (2011–2017).\\nFor his work on television, Hopkins received a British Academy Television Award for Best Actor for his performance in War and Peace (1972). He won two Primetime Emmy Awards for Outstanding Lead Actor in a Limited or Anthology Series or Movie for The Lindbergh Kidnapping Case (1976) and The Bunker (1981). Other notable projects include the BBC film The Dresser (2015), PBS' King Lear (2018), and the HBO series Westworld (2016–2018).\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Anthony_Hopkins'}, page_content=\"Sir Philip Anthony Hopkins (born 31 December 1937) is a Welsh actor. Considered one of Britain's most recognisable and prolific actors, he is known for his performances on the screen and stage. Hopkins has received numerous accolades, including two Academy Awards, four BAFTA Awards, two Primetime\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cb8a23-15de-4a86-ac94-d89d757b9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb76ff-fd3f-4f6d-a4f8-2087b0571040",
   "metadata": {},
   "source": [
    "3. Embedding and Storing Chunks\n",
    "Each document chunk is converted into a vector embedding using OpenAI Embeddings.\n",
    "All embeddings are stored in an in-memory vector store.\n",
    "vectorstore.add_documents(split_docs)\n",
    "This allows for fast similarity searches when a user query arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d2a507-7d01-4e96-a589-86d467773a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccfcb66c-5a93-4fcc-aaa2-7d9bbd0ecd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ecc57f37-abbd-4022-afbd-a6767dabca44',\n",
       " '0e6ad605-2bd5-438e-8a34-0fab99116fa7',\n",
       " '521c1e1e-6f52-4e6c-b670-748ab8e09900',\n",
       " 'c7c36634-816c-42f9-8e72-5923c1bd63f5',\n",
       " '5759db18-8ee1-41da-97ac-2c838d05ab13',\n",
       " 'd065e6e6-9ea0-42e9-83a6-b8a612acc948',\n",
       " 'b647cbeb-a97f-46ad-8363-03cf071a8160',\n",
       " 'fd11f740-7cba-4f79-81d4-fd9e947d9d6e',\n",
       " '4e62d335-3daa-4fc6-a700-972e6118f5d1',\n",
       " '728531b0-02ff-424d-b87f-f62aca66c3ce']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "document_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceeb3f9-e1a9-4cc4-8bf0-491e9a804c7f",
   "metadata": {},
   "source": [
    "4. Retriever Setup\n",
    "A retriever is created from the vector store.\n",
    "The retriever fetches the top k=3 most relevant documents based on similarity to the user query.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2226bf73-d12e-4c5d-8f7a-ce7b0484256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45826a04-6090-4ddb-b7c5-1ef1917b6add",
   "metadata": {},
   "source": [
    "5. Prompt Template Creation\n",
    "A chat prompt template is defined to guide the LLM:\n",
    "It receives both the context (retrieved documents) and the question.\n",
    "The model is instructed to reason based only on provided context.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are an assistant for question answering.\"),\n",
    "  (\"human\", \"Use the following context: {context}\\nQuestion: {question}\\nAnswer:\")\n",
    "])\n",
    "The template is a runnable object, so it can be invoked directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1305214f-57b3-47f0-bf46-e136290bf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an assistant for question-answering tasks.\"),\n",
    "    (\"human\", \"Use the following pieces of retrieved context to answer the question. \"\n",
    "              \"If you don't know the answer, just say that you don't know. \" \n",
    "              \"Use three sentences maximum and keep the answer concise. \"\n",
    "              \"\\n# Question: \\n-> {question} \"\n",
    "              \"\\n# Context: \\n-> {context} \"\n",
    "              \"\\n# Answer: \"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74c2ac2b-dc2f-4834-b221-c651ec7296ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an assistant for question-answering tasks.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \\n# Question: \\n-> ##QUESTION## \\n# Context: \\n-> ##CONTEXT## \\n# Answer: \", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke(\n",
    "    {\"context\": \"##CONTEXT##\", \"question\": \"##QUESTION##\"}\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937e3fab-43c4-4f65-8b9f-f6aad4b3cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    formatted = \"\\n\\n-> \".join(doc.page_content for doc in docs)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2af85d-1e75-4202-81cc-f852e535aa61",
   "metadata": {},
   "source": [
    "6. Generation Pipeline\n",
    "The complete flow:\n",
    "Format the retrieved documents into a single string for the context.\n",
    "Fill the prompt template with the question and context.\n",
    "Pass the resulting messages to the LLM.\n",
    "Retrieve the final answer.\n",
    "context = format_docs(docs)\n",
    "messages = prompt.invoke({\"context\": context, \"question\": \"When was The Silence of the Lambs released?\"})\n",
    "answer = llm.invoke(messages)\n",
    "Example output: \"The Silence of the Lambs was released in 1991.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d427129-6595-45dc-84b3-fdb1324ddebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46db098c-9cd4-4c7c-95c2-986ea31e61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When The Silence of the Lambs was released?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "messages = template.invoke({'question' : question, 'context' : context}).to_messages()\n",
    "answer = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91283588-6fa4-48de-bf17-b81d927909f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \n",
      "# Question: \n",
      "-> When The Silence of the Lambs was released? \n",
      "# Context: \n",
      "-> === 1990–1999: The Silence of the Lambs and film stardom ===\n",
      "\n",
      "-> Hopkins won acclaim among critics and audiences as the cannibalistic serial killer Hannibal Lecter in The Silence of the Lambs, for which he won the Academy Award for Best Actor in 1991, with Jodie Foster as Clarice Starling, who also won for Best Actress. The film won Best Picture, Best Director\n",
      "\n",
      "-> Actress. The film won Best Picture, Best Director and Best Adapted Screenplay, and Hopkins also picked up his first BAFTA for Best Actor. Hopkins reprised his role as Lecter twice; in Ridley Scott's Hannibal (2001), and Red Dragon (2002). His original portrayal of the character in The Silence of \n",
      "# Answer: \n"
     ]
    }
   ],
   "source": [
    "print(messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed503cf8-bfd3-44bc-a02e-8bad218a7c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Silence of the Lambs was released in 1991.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 242, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CO2usQXALSbi00sAWUiGpV0uL609x', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9f60728f-9407-4dc3-abf2-a52961d55010-0', usage_metadata={'input_tokens': 242, 'output_tokens': 13, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111afb10-4257-4e1e-bf22-55c5a5c9aaa2",
   "metadata": {},
   "source": [
    "7. Alternative: LCEL Version\n",
    "The RAG flow is also implemented using LCEL (LangChain Expression Language) for a more concise pipeline:\n",
    "Parallel retrieval of context and question.\n",
    "Formatting the final prompt.\n",
    "LLM invocation.\n",
    "rag_chain = (\n",
    "  {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "  | prompt\n",
    "  | llm\n",
    ")\n",
    "Example question: \"When was Anthony Hopkins born?\"\n",
    "Correct answer: \"December 31, 1937.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ee6840-b5b0-4fb0-93af-dd6b91c4c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ( \n",
    "    RunnableParallel(\n",
    "        context = retriever | format_docs, \n",
    "        question = RunnablePassthrough() \n",
    "    )\n",
    "    | template \n",
    "    | llm \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f3dc3a5-23bc-47d5-aa96-949c9609deef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Philip Anthony Hopkins was born on 31 December 1937.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 235, 'total_tokens': 248, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CO2uvqSPZyj9VxtarxhcceAKgHknc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--06ed11c9-c9da-45c9-9e3d-7c4f2538d494-0', usage_metadata={'input_tokens': 235, 'output_tokens': 13, 'total_tokens': 248, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"When he was born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1343cfb-1e9d-48d4-99cf-bf742295b267",
   "metadata": {},
   "source": [
    "8. Key Concepts Reinforced\n",
    "Augmenting LLMs with external knowledge improves factual accuracy.\n",
    "Chaining retrieval, prompt construction, and generation creates flexible, reusable workflows.\n",
    "LCEL simplifies the construction of complex pipelines with minimal code.\n",
    "9. Conclusion\n",
    "RAG pipelines enhance LLM outputs by grounding them in verified external documents.\n",
    "Document splitting, retrieval tuning, and structured prompting are critical for high-quality RAG systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f417d-c1f9-4808-a7e9-51f459e62a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
